{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data from http://jmcauley.ucsd.edu/data/tradesy/\n",
    "```\n",
    "wget http://jmcauley.ucsd.edu/data/tradesy/tradesy.json.gz\n",
    "wget http://jmcauley.ucsd.edu/data/tradesy/tradesy_item_urls.json.gz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback  \n",
    "   https://arxiv.org/abs/1510.01784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import gzip\n",
    "import struct\n",
    "from collections import defaultdict\n",
    "import gensim as gs\n",
    "import numpy as np\n",
    "try:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        print(\"notebook\")\n",
    "        from tqdm import tqdm_notebook as tqdm\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "except (NameError, RuntimeError):\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data = eval(gzip.open(\"./tradesy.json.gz\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(user_data, max_uid=1000000):\n",
    "    line_list =[]\n",
    "    user_list = []\n",
    "    item_dic = {}\n",
    "    few_buyers =[]\n",
    "    data = defaultdict(set)\n",
    "    for d  in user_data:\n",
    "        user_id = d[\"uid\"]\n",
    "        items = d[\"lists\"][\"bought\"]\n",
    "        \n",
    "        item_list = [int(i) for i in items]\n",
    "        if item_list:\n",
    "            max_i = max(item_list)\n",
    "            if max_i < max_uid:\n",
    "                user_list.append(user_id)\n",
    "                line_list.append(items)\n",
    "            \n",
    "    dictionary = gs.corpora.Dictionary(line_list)\n",
    "    dictionary.filter_extremes(no_below=1)\n",
    "    dictionary.compactify()\n",
    "    for u, items in zip(user_list, line_list):\n",
    "        data[u].update([dictionary.token2id[item] for item in items if item in dictionary.token2id])\n",
    "    for u,i in data.items():\n",
    "        if len(i) < 5:   # 5 same as the paper's\n",
    "            few_buyers.append(u)\n",
    "    for u in few_buyers:\n",
    "        del data[u]\n",
    "    d = {}\n",
    "    user_list = []\n",
    "    for idx,(u,i) in enumerate(data.items()):\n",
    "        d[idx] = i\n",
    "        user_list.append(u)\n",
    "    user_count = len(data.keys())\n",
    "    item_count = len(dictionary)\n",
    "    return user_count, item_count, d, dictionary, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test(data):\n",
    "    user_test = dict()\n",
    "    for u, i_list in data.items():\n",
    "        if i_list:\n",
    "            user_test[u] = np.random.choice(list(i_list))\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item count:  32807\n",
      "user count:  1076\n"
     ]
    }
   ],
   "source": [
    "max_uid=1000000\n",
    "user_count, item_count, data, dictionary,u_list  = load_data(user_data, max_uid)\n",
    "print(\"item count: \", item_count)\n",
    "print(\"user count: \", user_count)\n",
    "ui_test = generate_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file_name = \"./items.pickle\"\n",
    "#with open(file_name ,mode='wb') as f:\n",
    "#    pickle.dump(list(dictionary.token2id.keys()), f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readImageFeatures(path, dictionary):\n",
    "    f = open(path, 'rb')\n",
    "    imgs = {}\n",
    "    uids = dictionary.token2id.keys()\n",
    "    count = 0\n",
    "    while f:\n",
    "        userId = f.read(10)\n",
    "        userId = userId.strip()\n",
    "        if userId == '':\n",
    "            break\n",
    "        uid =  userId.decode('ascii')\n",
    "        if uid in uids:\n",
    "            feature = [struct.unpack('f', f.read(4)) for _ in range(4096)]\n",
    "            imgs[dictionary.token2id[uid]] = feature\n",
    "            count += 1\n",
    "            if count == len(uids):\n",
    "                break\n",
    "        else:\n",
    "            f.read(4*4096)\n",
    "            \n",
    "    file_name = \"./images.pickle\"\n",
    "    with open(file_name ,mode='wb') as f:\n",
    "        pickle.dump(image_features, f, protocol=4)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image_features = readImageFeatures(\"./image_features_tradesy.b\", dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"./images.pickle\"\n",
    "with open(file_name, mode='rb') as f:\n",
    "          image_features =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features[13348])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniform_sample_batch(train_ratings, item_count, image_features, sample_count=20000, batch_size=5):\n",
    "    for i in range(sample_count):\n",
    "        t = []\n",
    "        iv = []\n",
    "        jv = []\n",
    "        for b in range(batch_size):\n",
    "            u = random.sample(train_ratings.keys(), 1)[0]\n",
    "            i = random.sample(train_ratings[u], 1)[0]\n",
    "            j = random.randint(0, item_count-1)\n",
    "            while j in train_ratings[u]:\n",
    "                j = random.randint(0, item_count-1)\n",
    "            t.append([u, i, j])\n",
    "            iv.append(image_features[i])\n",
    "            jv.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(iv)), np.hstack(tuple(jv))\n",
    "\n",
    "def test_batch_generator_by_user(train_ratings, test_ratings, item_count, image_features, n_user=10):  \n",
    "    for u in np.random.choice(list(test_ratings.keys()), n_user):\n",
    "        i = test_ratings[u]\n",
    "        t = []\n",
    "        ilist = []\n",
    "        jlist = []\n",
    "        for j in range(item_count):\n",
    "            if j != test_ratings[u] and not (j in train_ratings[u]):\n",
    "                t.append([u, i, j])\n",
    "                ilist.append(image_features[i])\n",
    "                jlist.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(ilist)), np.hstack(tuple(jlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vbpr(user_count, item_count, latent_dim=20, latent_img_dim=128, learning_rate = 0.001,l2_regulization = 1.0):\n",
    "    image_dim = 4096\n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "    iv = tf.placeholder(tf.float32, [4096, None])\n",
    "    jv = tf.placeholder(tf.float32, [4096, None])\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        \n",
    "        user_w = weight_variable([user_count+1, latent_dim])\n",
    "        user_img_w = weight_variable([user_count+1, latent_img_dim])\n",
    "        item_w = weight_variable([item_count+1, latent_dim])\n",
    "        item_b = bias_variable([item_count+1, 1])\n",
    "        \n",
    "        u_e = tf.nn.embedding_lookup(user_w, u)\n",
    "        u_img = tf.nn.embedding_lookup(user_img_w, u)\n",
    "        \n",
    "        i_e = tf.nn.embedding_lookup(item_w, i)\n",
    "        i_b = tf.nn.embedding_lookup(item_b, i)\n",
    "        j_e = tf.nn.embedding_lookup(item_w, j)\n",
    "        j_b = tf.nn.embedding_lookup(item_b, j)\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "   \n",
    "        img_w = weight_variable([4096, latent_img_dim])\n",
    "\n",
    "        img_i_j = tf.matmul(tf.transpose(iv - jv), img_w)\n",
    "\n",
    "        x = i_b - j_b + tf.reduce_sum(tf.matmul(u_e, tf.transpose(i_e - j_e)), 1, keep_dims=True) +\\\n",
    "            tf.reduce_sum(tf.matmul(u_img, tf.transpose(img_i_j)),1, keep_dims=True)\n",
    "\n",
    "        auc = tf.reduce_mean(tf.to_float(x > 0))\n",
    "\n",
    "        l2_norm = tf.add_n([\n",
    "                tf.reduce_sum(tf.norm(u_e)), \n",
    "                tf.reduce_sum(tf.norm(u_img)),\n",
    "                tf.reduce_sum(tf.norm(i_e)),\n",
    "                tf.reduce_sum(tf.norm(j_e)),\n",
    "                tf.reduce_sum(tf.norm(img_w)),\n",
    "                tf.reduce_sum(tf.norm(i_b)),\n",
    "                tf.reduce_sum(tf.norm(j_b))\n",
    "            ])\n",
    "\n",
    "        loss = l2_regulization * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return u, i, j, iv, jv, loss, auc, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_n_user = 30 #len(ui_test)\n",
    "sample_count = 500\n",
    "n_epoch = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch  0  train_loss: 4.53547286701\n",
      "epoch  1  train_loss: 1.4604648037\n",
      "epoch  2  train_loss: 1.2721886456\n",
      "epoch  3  train_loss: 1.19367926931\n",
      "epoch  4  train_loss: 1.11112071371\n",
      "epoch  5  train_loss: 1.03883358324\n",
      "epoch  6  train_loss: 0.972820601225\n",
      "epoch  7  train_loss: 0.927639446139\n",
      "epoch  8  train_loss: 0.900886861086\n",
      "epoch  9  train_loss: 0.887057055473\n",
      "epoch  10  train_loss: 0.875901062369\n",
      "test_loss:  14.3292363803  auc:  0.41418132782\n",
      "epoch  11  train_loss: 0.867774270415\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    with tf.variable_scope('vbpr'):\n",
    "        u, i, j, iv, jv, loss, auc, train_op = vbpr(user_count, item_count,learning_rate = 0.0001)\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        \n",
    "        _loss_train = 0.0\n",
    "        for d,i_img,j_img  in uniform_sample_batch(data, item_count, image_features, sample_count=sample_count):\n",
    "            _loss, _ = session.run([loss, train_op], feed_dict={\n",
    "                    u:d[:,0], i:d[:,1], j:d[:,2], iv: i_img, jv: j_img\n",
    "                })\n",
    "            _loss_train += _loss\n",
    "            \n",
    "        print(\"epoch \", epoch, \" train_loss:\", _loss_train/sample_count)\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            _auc_all = 0.0\n",
    "            _loss_test = 0.0\n",
    "            for d,i_img,j_img in tqdm(test_batch_generator_by_user(data, ui_test, item_count, image_features, n_user=test_n_user)):\n",
    "                _loss, _auc = session.run([loss, auc], feed_dict={\n",
    "                        u:d[:,0], i:d[:,1], j:d[:,2], iv: i_img, jv: j_img\n",
    "                })\n",
    "                _loss_test += _loss\n",
    "                _auc_all += _auc\n",
    "            print( \"test_loss: \", _loss_test/test_n_user, \" auc: \", _auc_all/test_n_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (py3.6)",
   "language": "",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "1080fc6745044f54af9e7f4e42af5490": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "dc4ff4cf60184d568e78c9a167275602": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
