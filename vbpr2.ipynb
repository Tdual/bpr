{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#import lmdb\n",
    "import pickle\n",
    "import random\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import gensim as gs\n",
    "import numpy as np\n",
    "try:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        print(\"notebook\")\n",
    "        from tqdm import tqdm_notebook as tqdm\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "except (NameError, RuntimeError):\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data = eval(gzip.open(\"./tradesy.json.gz\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(user_data, max_uid=1000000):\n",
    "    line_list =[]\n",
    "    user_list = []\n",
    "    item_dic = {}\n",
    "    few_buyers =[]\n",
    "    data = defaultdict(set)\n",
    "    for d  in user_data:\n",
    "        user_id = d[\"uid\"]\n",
    "        items = d[\"lists\"][\"bought\"]\n",
    "        \n",
    "        item_list = [int(i) for i in items]\n",
    "        if item_list:\n",
    "            max_i = max(item_list)\n",
    "            if max_i < max_uid:\n",
    "                user_list.append(user_id)\n",
    "                line_list.append(items)\n",
    "            \n",
    "    dictionary = gs.corpora.Dictionary(line_list)\n",
    "    dictionary.filter_extremes(no_below=1)\n",
    "    dictionary.compactify()\n",
    "    for u, items in zip(user_list, line_list):\n",
    "        data[u].update([dictionary.token2id[item] for item in items if item in dictionary.token2id])\n",
    "    for u,i in data.items():\n",
    "        if len(i) < 5:   # 5 same as the paper's\n",
    "            few_buyers.append(u)\n",
    "    for u in few_buyers:\n",
    "        del data[u]\n",
    "    d = {}\n",
    "    user_list = []\n",
    "    for idx,(u,i) in enumerate(data.items()):\n",
    "        d[idx] = i\n",
    "        user_list.append(u)\n",
    "    user_count = len(data.keys())\n",
    "    item_count = len(dictionary)\n",
    "    return user_count, item_count, d, dictionary, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test(data):\n",
    "    user_test = dict()\n",
    "    for u, i_list in data.items():\n",
    "        if i_list:\n",
    "            user_test[u] = np.random.choice(list(i_list))\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item count:  32807\n",
      "user count:  1076\n"
     ]
    }
   ],
   "source": [
    "max_uid=1000000\n",
    "user_count, item_count, data, dictionary,u_list  = load_data(user_data, max_uid)\n",
    "print(\"item count: \", item_count)\n",
    "print(\"user count: \", user_count)\n",
    "ui_test = generate_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def readImageFeatures(path, dictionary):\n",
    "    f = open(path, 'rb')\n",
    "    imgs = {}\n",
    "    uids = dictionary.token2id.keys()\n",
    "    count = 0\n",
    "    while f:\n",
    "        userId = f.read(10)\n",
    "        userId = userId.strip()\n",
    "        if userId == '':\n",
    "            break\n",
    "        uid =  userId.decode('ascii')\n",
    "        if uid in uids:\n",
    "            feature = [struct.unpack('f', f.read(4)) for _ in range(4096)]\n",
    "            imgs[dictionary.token2id[uid]] = feature\n",
    "            count += 1\n",
    "            if count == len(uids):\n",
    "                break\n",
    "        else:\n",
    "            f.read(4*4096)\n",
    "            \n",
    "    file_name = \"./images.pickle\"\n",
    "    with open(file_name ,mode='wb') as f:\n",
    "        pickle.dump(image_features, f, protocol=4)\n",
    "    return imgs\n",
    "#image_features = readImageFeatures(\"./image_features_tradesy.b\", dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"./images.pickle\"\n",
    "with open(file_name, mode='rb') as f:\n",
    "          image_features =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features[13348])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniform_sample_batch(train_ratings, item_count, image_features, sample_count=20000, batch_size=5):\n",
    "    for i in range(sample_count):\n",
    "        t = []\n",
    "        iv = []\n",
    "        jv = []\n",
    "        for b in range(batch_size):\n",
    "            u = random.sample(train_ratings.keys(), 1)[0]\n",
    "            i = random.sample(train_ratings[u], 1)[0]\n",
    "            j = random.randint(0, item_count-1)\n",
    "            while j in train_ratings[u]:\n",
    "                j = random.randint(0, item_count-1)\n",
    "            t.append([u, i, j])\n",
    "            iv.append(image_features[i])\n",
    "            jv.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(iv)), np.hstack(tuple(jv))\n",
    "\n",
    "def test_batch_generator_by_user(train_ratings, test_ratings, item_count, image_features):  \n",
    "    for u in np.random.choice(list(test_ratings.keys()), 10):\n",
    "        i = test_ratings[u]\n",
    "        t = []\n",
    "        ilist = []\n",
    "        jlist = []\n",
    "        for j in range(item_count):\n",
    "            if j != test_ratings[u] and not (j in train_ratings[u]):\n",
    "                t.append([u, i, j])\n",
    "                ilist.append(image_features[i])\n",
    "                jlist.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(ilist)), np.hstack(tuple(jlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vbpr(user_count, item_count, hidden_dim=20, hidden_img_dim=128, learning_rate = 0.001,l2_regulization = 0.01):\n",
    "    image_dim = 4096\n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "    iv = tf.placeholder(tf.float32, [4096, None])\n",
    "    jv = tf.placeholder(tf.float32, [4096, None])\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        \n",
    "        user_emb_w = weight_variable([user_count+1, hidden_dim])\n",
    "        user_img_w = weight_variable([user_count+1, hidden_img_dim])\n",
    "        item_emb_w = weight_variable([item_count+1, hidden_dim])\n",
    "        item_b = bias_variable([item_count+1, 1])\n",
    "        \n",
    "        u_emb = tf.nn.embedding_lookup(user_emb_w, u)\n",
    "        u_img = tf.nn.embedding_lookup(user_img_w, u)\n",
    "        \n",
    "        i_emb = tf.nn.embedding_lookup(item_emb_w, i)\n",
    "        i_b = tf.nn.embedding_lookup(item_b, i)\n",
    "        j_emb = tf.nn.embedding_lookup(item_emb_w, j)\n",
    "        j_b = tf.nn.embedding_lookup(item_b, j)\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "   \n",
    "        img_emb_w = weight_variable([4096, hidden_img_dim])\n",
    "\n",
    "        img_i_j = tf.matmul(tf.transpose(iv - jv),img_emb_w)\n",
    "\n",
    "        # MF predict: u_i > u_j\n",
    "        x = i_b - j_b + tf.reduce_sum(tf.matmul(u_emb, tf.transpose(i_emb - j_emb)), 1, keep_dims=True) +\\\n",
    "            tf.reduce_sum(tf.matmul(u_img, tf.transpose(img_i_j)),1, keep_dims=True)\n",
    "\n",
    "        auc = tf.reduce_mean(tf.to_float(x > 0))\n",
    "\n",
    "        l2_norm = tf.add_n([\n",
    "                tf.reduce_sum(tf.norm(u_emb)), \n",
    "                tf.reduce_sum(tf.norm(u_img)),\n",
    "                tf.reduce_sum(tf.norm(i_emb)),\n",
    "                tf.reduce_sum(tf.norm(j_emb)),\n",
    "                tf.reduce_sum(tf.norm(img_emb_w)),\n",
    "                tf.reduce_sum(tf.norm(i_b)),\n",
    "                tf.reduce_sum(tf.norm(j_b))\n",
    "            ])\n",
    "\n",
    "        loss = l2_regulization * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return u, i, j, iv, jv, loss, auc, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    with tf.variable_scope('vbpr'):\n",
    "        u, i, j, iv, jv, loss, auc, train_op = vbpr(user_count, item_count)\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in tqdm(range(50000)):\n",
    "        \n",
    "        _loss_train = 0.0\n",
    "        sample_count = 500\n",
    "        for d,i_img,j_img  in uniform_sample_batch(data, item_count, image_features,sample_count=sample_count):\n",
    "            _loss, _ = session.run([loss, train_op], feed_dict={\n",
    "                    u:d[:,0], i:d[:,1], j:d[:,2],iv:i_img,jv:j_img\n",
    "                })\n",
    "            _loss_train += _loss\n",
    "        \n",
    "        if epoch % 100 != 0 or epoch == 0:\n",
    "            continue\n",
    "        print(\"epoch \", epoch)\n",
    "        print(\"train_loss:\", _loss_train/sample_count)\n",
    "        \n",
    "        _auc_all = 0\n",
    "        _loss_test = 0.0\n",
    "        _test_user_count = 10#len(ui_test)\n",
    "        for d,i_img,j_img in tqdm(test_batch_generator_by_user(data, ui_test, item_count, image_features)):\n",
    "            _loss, _auc = session.run([loss, auc], feed_dict={\n",
    "                    u:d[:,0], i:d[:,1], j:d[:,2],iv:i_img,jv:j_img\n",
    "                })\n",
    "            _loss_test += _loss\n",
    "            _auc_all += _auc\n",
    "        print( \"test_loss: \", _loss_test/_test_user_count, \" auc: \", _auc_all/_test_user_count)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (py3.6)",
   "language": "",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "1e7469cbf8b54ede82351306fb464bb4": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "508ac3a3ff6b4d2b81fedd3084799141": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "676dae670ab540d9bd1105800ef65f26": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "6ad4f3a00be644e3ba32af3a8bf33c91": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "7c5fd4b6905944cca272f16f42c4182a": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "8a0e7d0ddec3429a9fd3e5b92afe3549": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "998b5cd63c684d079b62cd9faead965b": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "9ef1616505c34a1fa9b8781cbcdfabd8": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "d3884c29f91c439a94af65a730d1bd40": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "f0d0b31278e24646a973cdb9e073f3a2": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
