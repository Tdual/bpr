{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#import lmdb\n",
    "import pickle\n",
    "import random\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import gensim as gs\n",
    "import numpy as np\n",
    "try:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        print(\"notebook\")\n",
    "        from tqdm import tqdm_notebook as tqdm\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "except (NameError, RuntimeError):\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data = eval(gzip.open(\"./tradesy.json.gz\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(user_data, max_uid=1000000):\n",
    "    line_list =[]\n",
    "    user_list = []\n",
    "    item_dic = {}\n",
    "    few_buyers =[]\n",
    "    data = defaultdict(set)\n",
    "    for d  in user_data:\n",
    "        user_id = d[\"uid\"]\n",
    "        items = d[\"lists\"][\"bought\"]\n",
    "        \n",
    "        item_list = [int(i) for i in items]\n",
    "        if item_list:\n",
    "            max_i = max(item_list)\n",
    "            if max_i < max_uid:\n",
    "                user_list.append(user_id)\n",
    "                line_list.append(items)\n",
    "            \n",
    "    dictionary = gs.corpora.Dictionary(line_list)\n",
    "    dictionary.filter_extremes(no_below=1)\n",
    "    dictionary.compactify()\n",
    "    for u, items in zip(user_list, line_list):\n",
    "        data[u].update([dictionary.token2id[item] for item in items if item in dictionary.token2id])\n",
    "    for u,i in data.items():\n",
    "        if len(i) < 5:   # 5 same as the paper's\n",
    "            few_buyers.append(u)\n",
    "    for u in few_buyers:\n",
    "        del data[u]\n",
    "    d = {}\n",
    "    user_list = []\n",
    "    for idx,(u,i) in enumerate(data.items()):\n",
    "        d[idx] = i\n",
    "        user_list.append(u)\n",
    "    user_count = len(data.keys())\n",
    "    item_count = len(dictionary)\n",
    "    return user_count, item_count, d, dictionary, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test(data):\n",
    "    user_test = dict()\n",
    "    for u, i_list in data.items():\n",
    "        if i_list:\n",
    "            user_test[u] = np.random.choice(list(i_list))\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item count:  32807\n",
      "user count:  1076\n"
     ]
    }
   ],
   "source": [
    "max_uid=1000000\n",
    "user_count, item_count, data, dictionary,u_list  = load_data(user_data, max_uid)\n",
    "print(\"item count: \", item_count)\n",
    "print(\"user count: \", user_count)\n",
    "ui_test = generate_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def readImageFeatures(path, dictionary):\n",
    "    f = open(path, 'rb')\n",
    "    imgs = {}\n",
    "    uids = dictionary.token2id.keys()\n",
    "    count = 0\n",
    "    while f:\n",
    "        userId = f.read(10)\n",
    "        userId = userId.strip()\n",
    "        if userId == '':\n",
    "            break\n",
    "        uid =  userId.decode('ascii')\n",
    "        if uid in uids:\n",
    "            feature = [struct.unpack('f', f.read(4)) for _ in range(4096)]\n",
    "            imgs[dictionary.token2id[uid]] = feature\n",
    "            count += 1\n",
    "            if count == len(uids):\n",
    "                break\n",
    "        else:\n",
    "            f.read(4*4096)\n",
    "            \n",
    "    file_name = \"./images.pickle\"\n",
    "    with open(file_name ,mode='wb') as f:\n",
    "        pickle.dump(image_features, f, protocol=4)\n",
    "    return imgs\n",
    "#image_features = readImageFeatures(\"./image_features_tradesy.b\", dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"./images.pickle\"\n",
    "with open(file_name, mode='rb') as f:\n",
    "          image_features =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features[13348])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniform_sample_batch(train_ratings, item_count, image_features, sample_count=20000, batch_size=5):\n",
    "    for i in range(sample_count):\n",
    "        t = []\n",
    "        iv = []\n",
    "        jv = []\n",
    "        for b in range(batch_size):\n",
    "            u = random.sample(train_ratings.keys(), 1)[0]\n",
    "            i = random.sample(train_ratings[u], 1)[0]\n",
    "            j = random.randint(0, item_count-1)\n",
    "            while j in train_ratings[u]:\n",
    "                j = random.randint(0, item_count-1)\n",
    "            t.append([u, i, j])\n",
    "            iv.append(image_features[i])\n",
    "            jv.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(iv)), np.hstack(tuple(jv))\n",
    "\n",
    "def test_batch_generator_by_user(train_ratings, test_ratings, item_count, image_features):  \n",
    "    for u in np.random.choice(list(test_ratings.keys()), 10):\n",
    "        i = test_ratings[u]\n",
    "        t = []\n",
    "        ilist = []\n",
    "        jlist = []\n",
    "        for j in range(item_count):\n",
    "            if j != test_ratings[u] and not (j in train_ratings[u]):\n",
    "                t.append([u, i, j])\n",
    "                ilist.append(image_features[i])\n",
    "                jlist.append(image_features[j])\n",
    "        yield np.asarray(t), np.hstack(tuple(ilist)), np.hstack(tuple(jlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vbpr(user_count, item_count, hidden_dim=20, hidden_img_dim=128, learning_rate = 0.001,l2_regulization = 1.0):\n",
    "    image_dim = 4096\n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "    iv = tf.placeholder(tf.float32, [4096, None])\n",
    "    jv = tf.placeholder(tf.float32, [4096, None])\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        \n",
    "        user_emb_w = weight_variable([user_count+1, hidden_dim])\n",
    "        user_img_w = weight_variable([user_count+1, hidden_img_dim])\n",
    "        item_emb_w = weight_variable([item_count+1, hidden_dim])\n",
    "        item_b = bias_variable([item_count+1, 1])\n",
    "        \n",
    "        u_emb = tf.nn.embedding_lookup(user_emb_w, u)\n",
    "        u_img = tf.nn.embedding_lookup(user_img_w, u)\n",
    "        \n",
    "        i_emb = tf.nn.embedding_lookup(item_emb_w, i)\n",
    "        i_b = tf.nn.embedding_lookup(item_b, i)\n",
    "        j_emb = tf.nn.embedding_lookup(item_emb_w, j)\n",
    "        j_b = tf.nn.embedding_lookup(item_b, j)\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "   \n",
    "        img_emb_w = weight_variable([4096, hidden_img_dim])\n",
    "\n",
    "        img_i_j = tf.matmul(tf.transpose(iv - jv),img_emb_w)\n",
    "\n",
    "        # MF predict: u_i > u_j\n",
    "        x = i_b - j_b + tf.reduce_sum(tf.matmul(u_emb, tf.transpose(i_emb - j_emb)), 1, keep_dims=True) +\\\n",
    "            tf.reduce_sum(tf.matmul(u_img, tf.transpose(img_i_j)),1, keep_dims=True)\n",
    "\n",
    "        auc = tf.reduce_mean(tf.to_float(x > 0))\n",
    "\n",
    "        l2_norm = tf.add_n([\n",
    "                tf.reduce_sum(tf.norm(u_emb)), \n",
    "                tf.reduce_sum(tf.norm(u_img)),\n",
    "                tf.reduce_sum(tf.norm(i_emb)),\n",
    "                tf.reduce_sum(tf.norm(j_emb)),\n",
    "                tf.reduce_sum(tf.norm(img_emb_w)),\n",
    "                tf.reduce_sum(tf.norm(i_b)),\n",
    "                tf.reduce_sum(tf.norm(j_b))\n",
    "            ])\n",
    "\n",
    "        loss = l2_regulization * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return u, i, j, iv, jv, loss, auc, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch  0\n",
      "train_loss: 0.767036357999\n",
      "epoch  1\n",
      "train_loss: 0.756872403204\n",
      "epoch  2\n",
      "train_loss: 0.745480528533\n",
      "epoch  3\n",
      "train_loss: 0.728582925439\n",
      "epoch  4\n",
      "train_loss: 0.697007082045\n",
      "epoch  5\n",
      "train_loss: 0.706574946404\n",
      "epoch  6\n",
      "train_loss: 0.672804654837\n",
      "epoch  7\n",
      "train_loss: 0.662746123075\n",
      "epoch  8\n",
      "train_loss: 0.640354195774\n",
      "epoch  9\n",
      "train_loss: 0.651526970088\n",
      "epoch  10\n",
      "train_loss: 0.650123256803\n",
      "epoch  11\n",
      "train_loss: 0.615438487798\n",
      "epoch  12\n",
      "train_loss: 0.614741210759\n",
      "epoch  13\n",
      "train_loss: 0.596611545801\n",
      "epoch  14\n",
      "train_loss: 0.593656293869\n",
      "epoch  15\n",
      "train_loss: 0.578509641141\n",
      "epoch  16\n",
      "train_loss: 0.604739527166\n",
      "epoch  17\n",
      "train_loss: 0.59274394235\n",
      "epoch  18\n",
      "train_loss: 0.576945156977\n",
      "epoch  19\n",
      "train_loss: 0.552970165789\n",
      "epoch  20\n",
      "train_loss: 0.579931971312\n",
      "epoch  21\n",
      "train_loss: 0.545179739475\n",
      "epoch  22\n",
      "train_loss: 0.541411174148\n",
      "epoch  23\n",
      "train_loss: 0.555442583472\n",
      "epoch  24\n",
      "train_loss: 0.528573757127\n",
      "epoch  25\n",
      "train_loss: 0.523736484125\n",
      "epoch  26\n",
      "train_loss: 0.533056502104\n",
      "epoch  27\n",
      "train_loss: 0.552151555195\n",
      "epoch  28\n",
      "train_loss: 0.528903541282\n",
      "epoch  29\n",
      "train_loss: 0.50459603186\n",
      "epoch  30\n",
      "train_loss: 0.5080240172\n",
      "epoch  31\n",
      "train_loss: 0.527564821377\n",
      "epoch  32\n",
      "train_loss: 0.478379105031\n",
      "epoch  33\n",
      "train_loss: 0.511328575626\n",
      "epoch  34\n",
      "train_loss: 0.507911408424\n",
      "epoch  35\n",
      "train_loss: 0.499440735817\n",
      "epoch  36\n",
      "train_loss: 0.460146111086\n",
      "epoch  37\n",
      "train_loss: 0.463690309748\n",
      "epoch  38\n",
      "train_loss: 0.451229497239\n",
      "epoch  39\n",
      "train_loss: 0.492647078007\n",
      "epoch  40\n",
      "train_loss: 0.511496081308\n",
      "epoch  41\n",
      "train_loss: 0.48581670554\n",
      "epoch  42\n",
      "train_loss: 0.456053643674\n",
      "epoch  43\n",
      "train_loss: 0.479486743525\n",
      "epoch  44\n",
      "train_loss: 0.457047000736\n",
      "epoch  45\n",
      "train_loss: 0.452994304508\n",
      "epoch  46\n",
      "train_loss: 0.457832465082\n",
      "epoch  47\n",
      "train_loss: 0.453392754719\n",
      "epoch  48\n",
      "train_loss: 0.43243557246\n",
      "epoch  49\n",
      "train_loss: 0.443607418865\n",
      "epoch  50\n",
      "train_loss: 0.486388209999\n",
      "epoch  51\n",
      "train_loss: 0.431819150656\n",
      "epoch  52\n",
      "train_loss: 0.421621662915\n",
      "epoch  53\n",
      "train_loss: 0.480264756039\n",
      "epoch  54\n",
      "train_loss: 0.456804980129\n",
      "epoch  55\n",
      "train_loss: 0.451439726114\n",
      "epoch  56\n",
      "train_loss: 0.443702244297\n",
      "epoch  57\n",
      "train_loss: 0.441348933011\n",
      "epoch  58\n",
      "train_loss: 0.415445054129\n",
      "epoch  59\n",
      "train_loss: 0.438673412591\n",
      "epoch  60\n",
      "train_loss: 0.434045466632\n",
      "epoch  61\n",
      "train_loss: 0.39528167519\n",
      "epoch  62\n",
      "train_loss: 0.419901177481\n",
      "epoch  63\n",
      "train_loss: 0.443457617998\n",
      "epoch  64\n",
      "train_loss: 0.426580761522\n",
      "epoch  65\n",
      "train_loss: 0.428512006819\n",
      "epoch  66\n",
      "train_loss: 0.471649919838\n",
      "epoch  67\n",
      "train_loss: 0.408883091167\n",
      "epoch  68\n",
      "train_loss: 0.421226889238\n",
      "epoch  69\n",
      "train_loss: 0.390417262048\n",
      "epoch  70\n",
      "train_loss: 0.434187740505\n",
      "epoch  71\n",
      "train_loss: 0.423492554367\n",
      "epoch  72\n",
      "train_loss: 0.415394832477\n",
      "epoch  73\n",
      "train_loss: 0.409485909194\n",
      "epoch  74\n",
      "train_loss: 0.414460481927\n",
      "epoch  75\n",
      "train_loss: 0.434041870058\n",
      "epoch  76\n",
      "train_loss: 0.41527866447\n",
      "epoch  77\n",
      "train_loss: 0.395833807275\n",
      "epoch  78\n",
      "train_loss: 0.394300219983\n",
      "epoch  79\n",
      "train_loss: 0.392433713555\n",
      "epoch  80\n",
      "train_loss: 0.403716040999\n",
      "epoch  81\n",
      "train_loss: 0.406050172567\n",
      "epoch  82\n",
      "train_loss: 0.406355942786\n",
      "epoch  83\n",
      "train_loss: 0.413381068379\n",
      "epoch  84\n",
      "train_loss: 0.407668320924\n",
      "epoch  85\n",
      "train_loss: 0.401115878522\n",
      "epoch  86\n",
      "train_loss: 0.432341285676\n",
      "epoch  87\n",
      "train_loss: 0.39761060667\n",
      "epoch  88\n",
      "train_loss: 0.394328918487\n",
      "epoch  89\n",
      "train_loss: 0.416398811162\n",
      "epoch  90\n",
      "train_loss: 0.422322055012\n",
      "epoch  91\n",
      "train_loss: 0.376202107966\n",
      "epoch  92\n",
      "train_loss: 0.386673287123\n",
      "epoch  93\n",
      "train_loss: 0.383830448806\n",
      "epoch  94\n",
      "train_loss: 0.393389550447\n",
      "epoch  95\n",
      "train_loss: 0.388034013212\n",
      "epoch  96\n",
      "train_loss: 0.372955392659\n",
      "epoch  97\n",
      "train_loss: 0.401490751445\n",
      "epoch  98\n",
      "train_loss: 0.366377569884\n",
      "epoch  99\n",
      "train_loss: 0.385338429809\n",
      "epoch  100\n",
      "train_loss: 0.383352274328\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    with tf.variable_scope('vbpr'):\n",
    "        u, i, j, iv, jv, loss, auc, train_op = vbpr(user_count, item_count,learning_rate = 0.0001)\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in tqdm(range(50000)):\n",
    "        \n",
    "        _loss_train = 0.0\n",
    "        sample_count = 500\n",
    "        for d,i_img,j_img  in uniform_sample_batch(data, item_count, image_features,sample_count=sample_count):\n",
    "            _loss, _ = session.run([loss, train_op], feed_dict={\n",
    "                    u:d[:,0], i:d[:,1], j:d[:,2],iv:i_img,jv:j_img\n",
    "                })\n",
    "            _loss_train += _loss\n",
    "            \n",
    "        print(\"epoch \", epoch)\n",
    "        print(\"train_loss:\", _loss_train/sample_count)\n",
    "        if epoch % 100 != 0 or epoch == 0:\n",
    "            continue\n",
    "        \n",
    "        _auc_all = 0\n",
    "        _loss_test = 0.0\n",
    "        _test_user_count = 10#len(ui_test)\n",
    "        for d,i_img,j_img in tqdm(test_batch_generator_by_user(data, ui_test, item_count, image_features)):\n",
    "            _loss, _auc = session.run([loss, auc], feed_dict={\n",
    "                    u:d[:,0], i:d[:,1], j:d[:,2],iv:i_img,jv:j_img\n",
    "                })\n",
    "            _loss_test += _loss\n",
    "            _auc_all += _auc\n",
    "        print( \"test_loss: \", _loss_test/_test_user_count, \" auc: \", _auc_all/_test_user_count)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (py3.6)",
   "language": "",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "1e7469cbf8b54ede82351306fb464bb4": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "508ac3a3ff6b4d2b81fedd3084799141": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "67845fb0532542d38215ca025f94b57e": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "6ad4f3a00be644e3ba32af3a8bf33c91": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "7c55a215d31d4a47a184b77af350ce31": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "7c5fd4b6905944cca272f16f42c4182a": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "8a0e7d0ddec3429a9fd3e5b92afe3549": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "97aa94f2a0e24dc489327ccc9cddb3cc": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "998b5cd63c684d079b62cd9faead965b": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "9ef1616505c34a1fa9b8781cbcdfabd8": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "d3884c29f91c439a94af65a730d1bd40": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "f0d0b31278e24646a973cdb9e073f3a2": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
