{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://grouplens.org/datasets/movielens/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gensim as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = defaultdict(set)\n",
    "    max_u_id = -1\n",
    "    max_i_id = -1\n",
    "    with open(data_path, 'r') as f:\n",
    "        f.readline()\n",
    "        for idx, line in enumerate(f):\n",
    "            u, i, _, _ = line.split(\",\")\n",
    "            u = int(u)\n",
    "            i = int(i)\n",
    "            data[u].add(i)\n",
    "            max_u_id = max(u, max_u_id)\n",
    "            max_i_id = max(i, max_i_id)\n",
    "            if idx == 1000:\n",
    "                break\n",
    "    return max_u_id, max_i_id, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_test(data):\n",
    "    user_test = dict()\n",
    "    for u, i_list in data.items():\n",
    "        user_test[u] = np.random.choice(list(i_list))\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_data(data_path):\n",
    "    line_list =[]\n",
    "    user_list = []\n",
    "    item_dic = {}\n",
    "    few_buyers =[]\n",
    "    data = defaultdict(set)\n",
    "    with open(data_path, 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line = line[:-1] # remove \\n\n",
    "            l = line.split(\",\")\n",
    "            user_id = l[0]\n",
    "            items = l[1:]\n",
    "            user_list.append(user_id)\n",
    "            line_list.append(items)\n",
    "    dictionary = gs.corpora.Dictionary(line_list)\n",
    "    for u, items in zip(user_list, line_list):\n",
    "        data[u].update([dictionary.token2id[item] for item in items])\n",
    "    for u,i in data.items():\n",
    "        if len(i) < 10:\n",
    "            few_buyers.append(u)\n",
    "    for u in few_buyers:\n",
    "        del data[u]\n",
    "    d = {}\n",
    "    user_list = []\n",
    "    for idx,(u,i) in enumerate(data.items()):\n",
    "        d[idx] = i\n",
    "        user_list.append(u)\n",
    "    user_count = len(data.keys())\n",
    "    item_count = len(dictionary)\n",
    "    return (user_count, item_count, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_count, item_count, data = map_data(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30572"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5922"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_path = \"./ml-20m/ratings.csv\"\n",
    "#user_count, item_count, data = load_data(data_path)\n",
    "user_ratings_test = generate_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_batch(data, user_ratings_test, item_count, batch_size=512):\n",
    "    t = []\n",
    "    for _ in range(batch_size):\n",
    "        u = np.random.choice(list(data.keys()))\n",
    "        i = np.random.choice(list(data[u]))\n",
    "        while i == user_ratings_test[u]:\n",
    "            i = np.random.choice(list(data[u]))\n",
    "        \n",
    "        j = np.random.randint(1, item_count+1)\n",
    "        while j in data[u]:\n",
    "            j = np.random.randint(1, item_count+1)\n",
    "        t.append([u, i, j])\n",
    "    return np.asarray(t)\n",
    "\n",
    "def generate_test_batch(user_ratings, user_ratings_test, item_count):\n",
    "    for u in np.random.choice(list(user_ratings.keys()),300):\n",
    "        t = []\n",
    "        i = user_ratings_test[u]\n",
    "        for j in range(1, item_count+1):\n",
    "            if not (j in user_ratings[u]):\n",
    "                t.append([u, i, j])\n",
    "        yield np.asarray(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bpr(user_count, item_count, hidden_dim, batch_size=512):\n",
    "    \n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    user_w = weight_variable([user_count+1, hidden_dim])\n",
    "    item_w = weight_variable([item_count+1, hidden_dim])\n",
    "    item_b = bias_variable([item_count+1, 1])\n",
    "        \n",
    "        \n",
    "    u_e = tf.nn.embedding_lookup(user_w, u)\n",
    "        \n",
    "    i_e = tf.nn.embedding_lookup(item_w, i)\n",
    "    i_b = tf.nn.embedding_lookup(item_b, i)\n",
    "        \n",
    "    j_e = tf.nn.embedding_lookup(item_w, j)\n",
    "    j_b = tf.nn.embedding_lookup(item_b, j)\n",
    "    \n",
    "    # MF \n",
    "    x = i_b - j_b + tf.reduce_sum(tf.matmul(u_e, tf.transpose((i_e - j_e))), 1, keep_dims=True)\n",
    "    \n",
    "    \n",
    "    auc_per_user = tf.reduce_mean(tf.cast(x > 0,\"float\"))\n",
    "    \n",
    "    l2_norm = tf.add_n([\n",
    "            tf.reduce_sum(tf.norm(u_e)), \n",
    "            tf.reduce_sum(tf.norm(i_e)),\n",
    "            tf.reduce_sum(tf.norm(j_e))\n",
    "        ])\n",
    "    \n",
    "    regu_rate = 0.0001\n",
    "    loss = - tf.reduce_mean(tf.log(tf.sigmoid(x))) + regu_rate * l2_norm\n",
    "    \n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    return u, i, j, auc_per_user, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:  0 , loss:  0.0165430002068\n",
      "\n",
      "test loss:  0.00765047 , test auc:  0.873333333333\n",
      "\n",
      "epoch:  1 , loss:  0.000888434192544\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    u, i, j, auc_per_user, loss, train_op = bpr(user_count, item_count, 20)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in range(10):\n",
    "        _batch_loss = 0\n",
    "        for index in tqdm(range(2000)): \n",
    "            uij = generate_train_batch(data, user_ratings_test, item_count)\n",
    "            _loss, _ = session.run([loss, train_op], feed_dict={u:uij[:,0], i:uij[:,1], j:uij[:,2]})\n",
    "            _batch_loss += _loss\n",
    "                   \n",
    "        print(\"epoch: \", epoch, \", loss: \", _batch_loss / (index+1))\n",
    "\n",
    "\n",
    "        _auc_sum = 0.0\n",
    "        user_count = 0\n",
    "        for t_uij in tqdm(generate_test_batch(data, user_ratings_test, item_count)):\n",
    "            _auc_per_user, _test_loss = session.run([auc_per_user, loss],feed_dict={u:t_uij[:,0], i:t_uij[:,1], j:t_uij[:,2]})\n",
    "            user_count += 1\n",
    "            _auc_sum += _auc_per_user\n",
    "            \n",
    "            _auc = _auc_sum/user_count # eq (1) in the paper\n",
    "            \n",
    "        print(\"test loss: \", _test_loss, \", test auc: \", _auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (py3.6)",
   "language": "",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "049251cfc082413884e34ca26d6c79d3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "0594eac8483f4f57861dda359e4fbb06": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "0c06df397e76459e8da16e25f61b021f": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "13d769b933eb42b18f1c223f4f823469": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "174cde219dbe436eb8cf9402fae3b967": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "1cf6c4b7a7114dd18abadc2483bb76ac": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "32ccf38c3fa248f085fbe724b6619667": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "4145c4f6f68d49e4bb70f505177ad387": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "460d943e1e4c4d56a7086937c2ea0921": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "4843c9e1e389446ab2dc877dca7d3e00": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "4aefe2e7d75440958a4af61a77664c77": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "4c09e2e9c65142d3821b0a4e9bc51a04": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "4e84fdeee783436ebaef6f41c74dcc2b": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "5fbdd8c599f04cd889278ddb538526eb": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "629f008643ae4a05b5ac8453a60f17ea": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6326298842c64c0487fce533eb42ade4": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "851a1166a73746b68e2c7bd94cebe68a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "9536ea82d5e946179486ef9a68b9c62e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9c4b0308f5764349925986041d8033f3": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "a4ffa8660f6447b6b123a2e5e920e6e6": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "c2784f855e0643e89ffe0e6241a3ff84": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c5c3f7830b114a979ff359220b447dcd": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "cb8da0a651dd490c94893c303a2361a3": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "d178e2345b3545599e24c88f760fd615": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "d48c183316234c1f8c0239ed06e08adc": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "d7980e47e6cf479f9b4ace4a158ea098": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d9adc32665dc42429f73c15e9c9b7be0": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "e007c37ddea8447b8d9cc21d3f00abd4": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "ec9605276be743a6b6df6de003af5a32": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f3c56207501641efa3cda0c95ab4eb9a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "f5202aab349a4d79b18861547e1e7acb": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
